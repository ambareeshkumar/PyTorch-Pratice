{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/37/04/a5cd83baccbf2d4329990ec06b8abf3a644e1559a7b1f764f42d2cb77d51/torch-2.3.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached torch-2.3.0-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/53/8a/864c3969af219a95213a5065d453313a96598e7c744b859e99b6ac134e16/torchvision-0.18.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached torchvision-0.18.0-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/f7/06/34addade5c69063d89d67ff810fd6197c28f93d9cf089c51d198562827b8/torchaudio-2.3.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached torchaudio-2.3.0-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/41/24/0b023b6537dfc9bae2c779353998e3e99ac7dfff4222fc6126650e93c3f3/filelock-3.14.0-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Obtaining dependency information for typing-extensions>=4.8.0 from https://files.pythonhosted.org/packages/01/f3/936e209267d6ef7510322191003885de524fc48d1b43269810cd589ceaf5/typing_extensions-4.11.0-py3-none-any.whl.metadata\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Obtaining dependency information for sympy from https://files.pythonhosted.org/packages/d2/05/e6600db80270777c4a64238a98d442f0fd07cc8915be2a1c16da7f2b9e74/sympy-1.12-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/38/e9/5f72929373e1a0e8d142a130f3f97e6ff920070f87f91c4e13e40e0fba5a/networkx-3.3-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Obtaining dependency information for jinja2 from https://files.pythonhosted.org/packages/31/80/3a54838c3fb461f6fec263ebf3a3a41771bd05190238de3486aae8540c36/jinja2-3.1.4-py3-none-any.whl.metadata\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/ba/a3/16e9fe32187e9c8bc7f9b7bcd9728529faa725231a0c96f2f98714ff2fc5/fsspec-2024.5.0-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Obtaining dependency information for mkl<=2021.4.0,>=2021.1.1 from https://files.pythonhosted.org/packages/fe/1c/5f6dbf18e8b73e0a5472466f0ea8d48ce9efae39bd2ff38cebf8dce61259/mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Obtaining dependency information for numpy from https://files.pythonhosted.org/packages/16/2e/86f24451c2d530c88daf997cb8d6ac622c1d40d19f5a031ed68a4b73a374/numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Obtaining dependency information for pillow!=8.3.*,>=5.3.0 from https://files.pythonhosted.org/packages/d3/23/3927d888481ff7c44fdbca3bc2a2e97588c933db46723bf115201377c436/pillow-10.3.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached pillow-10.3.0-cp312-cp312-win_amd64.whl.metadata (9.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Obtaining dependency information for intel-openmp==2021.* from https://files.pythonhosted.org/packages/6f/21/b590c0cc3888b24f2ac9898c41d852d7454a1695fbad34bee85dba6dc408/intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Obtaining dependency information for tbb==2021.* from https://files.pythonhosted.org/packages/7b/2d/1e1c70fae8ace27e6200fb71c2372a9aeac2baba474b1609d7d466e969b4/tbb-2021.12.0-py3-none-win_amd64.whl.metadata\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Obtaining dependency information for MarkupSafe>=2.0 from https://files.pythonhosted.org/packages/3f/14/c3554d512d5f9100a95e737502f4a2323a1959f6d0d01e0d0997b35f7b10/MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Obtaining dependency information for mpmath>=0.19 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.3.0-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "Using cached torchvision-0.18.0-cp312-cp312-win_amd64.whl (1.2 MB)\n",
      "Using cached torchaudio-2.3.0-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached pillow-10.3.0-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, typing-extensions, sympy, pillow, numpy, networkx, mkl, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.14.0 fsspec-2024.5.0 intel-openmp-2021.4.0 jinja2-3.1.4 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 numpy-1.26.4 pillow-10.3.0 sympy-1.12 tbb-2021.12.0 torch-2.3.0 torchaudio-2.3.0 torchvision-0.18.0 typing-extensions-4.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Installing pytorch\n",
    "\n",
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Tensors  is a multi-dimensional matrix containing elements of a single data type. It can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.empty(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It creates an 2D Tensor\n",
      "tensor([[inf, 0.]])\n",
      "It creates a tensor with the given shape, but the values are not initialized. The values are random and depend on the state of the memory.\n"
     ]
    }
   ],
   "source": [
    "print('It creates an 2D Tensor')\n",
    "x = torch.empty(1,2)\n",
    "print(x)\n",
    "print('It creates a tensor with the given shape, but the values are not initialized. The values are random and depend on the state of the memory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(4,2, dtype = torch.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another Way to create a tensor\n",
    "torch.tensor([2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the size of Tensor\n",
    "x = torch.tensor([2,3,4])\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 5, 7])\n",
      "inplace_addition: tensor([3, 5, 7])\n"
     ]
    }
   ],
   "source": [
    "# Perform operations on Tensors\n",
    "\n",
    "x = torch.tensor([2,3,4])\n",
    "y = torch.tensor([1,2,3])\n",
    "\n",
    "z = x + y # It will do element wise addition\n",
    "print(z)\n",
    "\n",
    "inplace_addition = x.add_(y) # It will do inplace addition\n",
    "print(f'inplace_addition: {inplace_addition}')  # Anything with underscore is inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, -1,  1])\n",
      "inplace_subtraction: tensor([ 1, -1,  1])\n"
     ]
    }
   ],
   "source": [
    "#  It will do element wise subtraction\n",
    "x = torch.tensor([2,1,4])\n",
    "y = torch.tensor([1,2,3])\n",
    "\n",
    "z = x - y \n",
    "print(z)\n",
    "\n",
    "inplace_subtraction = x.sub_(y) # It will do inplace subtraction\n",
    "print(f'inplace_subtraction: {inplace_subtraction}')  # Anything with underscore is inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2,  2, 12])\n",
      "inplace_multiplication: tensor([ 2,  2, 12])\n"
     ]
    }
   ],
   "source": [
    "# It will do element wise multiplication\n",
    "\n",
    "x = torch.tensor([2,1,4]) \n",
    "y = torch.tensor([1,2,3])\n",
    "\n",
    "z = x * y\n",
    "print(z)\n",
    "\n",
    "inplace_multiplication = x.mul_(y) # It will do inplace multiplication\n",
    "print(f'inplace_multiplication: {inplace_multiplication}')  # Anything with underscore is inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2857, 0.5000, 1.3333], dtype=torch.float64)\n",
      "inplace_division: tensor([0.2857, 0.5000, 1.3333], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# It will do element wise division\n",
    "\n",
    "x = torch.tensor([2,1,4], dtype=float)\n",
    "y = torch.randint(1, 10, size=x.size(), dtype=float)  # Specify the high argument for torch.randint()\n",
    "\n",
    "z = x/y\n",
    "print(z)\n",
    "\n",
    "inplace_division = x.div_(y) # It will do inplace division\n",
    "print(f'inplace_division: {inplace_division}')  # Anything with underscore is inplace operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3840, 0.2079, 0.7426],\n",
      "        [0.2038, 0.8460, 0.4431],\n",
      "        [0.5505, 0.2135, 0.5048],\n",
      "        [0.9269, 0.8213, 0.6684],\n",
      "        [0.6727, 0.7803, 0.7511]])\n",
      "tensor([0.3840, 0.2038, 0.5505, 0.9269, 0.6727])\n",
      "tensor([0.3840, 0.2079, 0.7426])\n",
      "tensor([[0.2079],\n",
      "        [0.8460],\n",
      "        [0.2135],\n",
      "        [0.8213],\n",
      "        [0.7803]])\n",
      "tensor(0.8460)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3)\n",
    "print(x)\n",
    "\n",
    "# Slicing the tensor syntax is same as numpy array slicing\n",
    "\n",
    "print(x[:,0]) # It will give the first column\n",
    "print(x[0,:]) # It will give the first row\n",
    "\n",
    "print(x[:,1:2]) # It will give the second column\n",
    "\n",
    "print(x[1,1].item()) # It will give the value at 1,1 index. It will only work for one number for multiple numbers use x[1,1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape the tensor: tensor([0.6861, 0.0680, 0.9674, 0.3410, 0.9940, 0.5120, 0.6434, 0.8760, 0.8992,\n",
      "        0.0856, 0.1700, 0.4217, 0.1166, 0.8901, 0.6700, 0.2268])\n",
      "reshape the tensor: tensor([[0.6861, 0.0680, 0.9674, 0.3410, 0.9940, 0.5120, 0.6434, 0.8760],\n",
      "        [0.8992, 0.0856, 0.1700, 0.4217, 0.1166, 0.8901, 0.6700, 0.2268]])\n"
     ]
    }
   ],
   "source": [
    "# View function is used to reshape the tensor to different shape but the number of elements should be same in both the shapes.\n",
    "\n",
    "x = torch.rand(4,4)\n",
    "y = x.view(16) # it has transformed the 4x4 tensor to 16x1 tensor\n",
    "\n",
    "print(f'reshape the tensor: {y}') \n",
    "\n",
    "#Use -1 to infer the shape of the tensor automatically\n",
    "y = x.view(-1,8) # it has transformed the 4x4 tensor to 2x8 tensor\n",
    "print(f'reshape the tensor: {y}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original numpy array: [1. 1. 1. 1. 1.]\n",
      "change numpy array to tensor: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# change numpy array to tensor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "print(f'Original numpy array: {a}')\n",
    "print(f'change numpy array to tensor: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor: tensor([[0.8337, 0.6743],\n",
      "        [0.2616, 0.4905],\n",
      "        [0.0151, 0.1021],\n",
      "        [0.7541, 0.9332],\n",
      "        [0.6730, 0.9271]])\n",
      "change tensor to numpy array: [[0.8337192  0.67425394]\n",
      " [0.2616135  0.49046916]\n",
      " [0.01508915 0.10206342]\n",
      " [0.7541462  0.9332395 ]\n",
      " [0.6729545  0.9270863 ]], type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# change tensor to numpy array\n",
    "a = torch.rand(5,2)\n",
    "print(f'Original tensor: {a}')\n",
    "\n",
    "b = a.numpy()\n",
    "print(f'change tensor to numpy array: {b}, type: {type(b)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available: False\n"
     ]
    }
   ],
   "source": [
    "# Check GPU is available or not\n",
    "\n",
    "print(f'GPU is available: {torch.cuda.is_available()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU not available performing on CPU\n",
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# If GPU is available then move the tensor to GPU\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    x = torch.ones(5, device=device)\n",
    "    y = torch.ones(5)\n",
    "    y = y.to(device)\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to('cpu', torch.double))\n",
    "else:\n",
    "    print(f'GPU not available performing on CPU')\n",
    "    x = torch.ones(5)\n",
    "    y = torch.ones(5)\n",
    "    z = x + y\n",
    "    print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
